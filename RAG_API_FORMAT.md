# RAG Bot API Format

Your RAG bot server should run on `localhost:8000` and accept POST requests to `/message` endpoint.

## Expected Request Format

```json
POST http://localhost:8000/message
Content-Type: application/json

{
  "message": "What are Shaurya's skills?",
  "language": "en"  // or "hi" for Hindi
}
```

## Expected Response Format

```json
{
  "response": "Shaurya is a full-stack developer with expertise in React, Node.js, Three.js, and modern web technologies..."
}
```

OR

```json
{
  "message": "Shaurya is a full-stack developer with expertise in React, Node.js, Three.js, and modern web technologies..."
}
```

## Enhanced Error Handling

The frontend now provides user-friendly error messages for different scenarios:

### Connection Errors (Server Down)
- **Triggers:** ECONNREFUSED, ERR_NETWORK
- **User Message:** "üîß Server is down - We'll be right back! Our RAG bot endpoint is currently unavailable..."

### Token Expiration (Gemini LLM)
- **HTTP Status:** 401, 403
- **User Message:** "üîë Sorry, LLM tokens expired! Our Gemini LLM tokens have reached their limit. We'll be back online when the tokens are recharged!"

### Rate Limiting
- **HTTP Status:** 429
- **User Message:** "üö¶ Rate limit exceeded. Too many requests at the moment. Our Gemini LLM needs a short break..."

### Server Errors
- **HTTP Status:** 500
- **User Message:** "‚ö†Ô∏è Internal server error. Our RAG bot encountered an internal issue. Don't worry, Shaurya will fix this soon!"

### Service Unavailable
- **HTTP Status:** 503
- **User Message:** "üîß Service temporarily unavailable. Our custom RAG system is undergoing maintenance..."

### Timeout Errors
- **Trigger:** 30+ second timeout
- **User Message:** "‚è±Ô∏è Processing timeout. The request took too long to process. Our Gemini LLM might be handling a complex query..."

## Features Integrated

- ‚úÖ Axios HTTP client for API calls
- ‚úÖ Language context (EN/HI) sent to server
- ‚úÖ Enhanced error handling with user-friendly messages
- ‚úÖ Loading states ("Consulting Gemini via RAG bot...")
- ‚úÖ Voice synthesis for responses
- ‚úÖ Bilingual support
- ‚úÖ Custom RAG bot branding and info display
- ‚úÖ Specific Gemini LLM token expiration handling
- ‚úÖ Detailed system information in chat header

## UI Enhancements

### Chat Header
- Displays "AI Assistant" with online status
- Shows "üöÄ Custom RAG Bot ‚Ä¢ Gemini LLM ‚Ä¢ Built by Shaurya"
- Real-time status indicators (online/listening/speaking)

### Chat Footer
- Info banner: "üí° Powered by custom RAG bot ‚Ä¢ Built in-house by Shaurya"

### Greeting Message
- "Hello! I'm your AI assistant powered by a custom RAG bot built from scratch by Shaurya using Gemini LLM"

### Loading States
- "Consulting Gemini via RAG bot..." with animated dots

## Test Your Server

1. Start your RAG bot server on port 8000
2. Test with curl:
```bash
curl -X POST http://localhost:8000/message \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello", "language": "en"}'
```

3. Expected response:
```json
{"response": "Hello! How can I help you?"}
```

## Testing Error Responses

### Test Token Expiration
Return HTTP 401/403 from your server:
```json
{"error": "Token expired", "message": "Gemini API quota exceeded"}
```

### Test Rate Limiting
Return HTTP 429 from your server:
```json
{"error": "Rate limited", "message": "Too many requests"}
```

## Usage

Once your server is running, the AI assistant will:
1. Send user messages to your RAG bot with language context
2. Display the RAG bot's responses with proper formatting
3. Handle errors gracefully with specific messages for different scenarios
4. Show detailed branding about your custom RAG system
5. Provide real-time feedback during API calls